{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg_djFWkANUf"
      },
      "source": [
        "## 00. PyTorch Fundamentals\n",
        "Resoruce Notebook https://www.learnpytorch.io/00_pytorch_fundamentals/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODM4AfevU88b",
        "outputId": "9f45d77f-2eb9-49df-992f-9c392665449f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.3.1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Changing from CPU to MPS\n",
        "# torch.set_default_device(torch.device(\"mps\"))\n",
        "# Fundamental Data Science Packages:\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rex0bNggGlNE"
      },
      "source": [
        "If your google instance restarts or you reconfigure your resources, you need to re-run the packages above ^"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn9bmpUaEiZ2"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "### Creating Tensors\n",
        "PyTorch tensors are created using `torch.tensor()` .\n",
        "\n",
        "`torch.tensor()` is the most common class in PyTorch\n",
        "\n",
        "https://pytorch.org/docs/stable/tensors.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lPF34JqFUkK",
        "outputId": "80bea5da-4da9-4b0d-e6b8-5190b2db704b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JlZi_PLHBK_",
        "outputId": "6a04c160-b9a5-466e-9b0d-51b63a2d05c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIDA-6mvHHqq"
      },
      "source": [
        "scalar has no deminsions, its just a single number.\n",
        "If you want to get the number out of a tensor type:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waiPz5uEHSns",
        "outputId": "35dd661e-bf46-48ac-d6c0-43f8dccbfc29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get tensor back as Python Int\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEgTIEloHmYE",
        "outputId": "2b5c82cd-2a67-48b6-f94d-263fd7e37acf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7,7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSoZn2gBH67_",
        "outputId": "06431421-61f0-46d3-9676-f915323e03d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# It has one deminsion\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hInEeSEjIVAc",
        "outputId": "a428af4d-5725-414a-eae2-75fbaad6c10a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtc4FiKrIK12"
      },
      "source": [
        "To know how many deminsion it has, count the number of [] pairs\n",
        "\n",
        "shape by deminsion\n",
        "\n",
        "2 by 1 elements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JEtMxnWIide",
        "outputId": "83ea13fd-88fb-4ab1-ba46-e192c3a71dd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix\n",
        "MATRIX = torch.tensor([[7,8],[9,10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZkaxfV5JCvR"
      },
      "source": [
        "All are tensors: Scalar, Vector, Matrix\n",
        "\n",
        "Anytime you encode data into numbers, it's of a tensor data type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bswTTIlhJhg9",
        "outputId": "4d05aded-615a-424b-a5e6-616d804f0e18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuO9EG3RJkMO",
        "outputId": "54d77af9-f9fb-4f82-9152-06ad7203af10"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aj9hjcZUJqxS",
        "outputId": "90d0979d-895a-4823-902b-ba344a06677b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWdEBS5mJuVt",
        "outputId": "6c259980-7934-4985-dd6b-7b173cd0e8a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [8, 2, 1]]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# TENSOR\n",
        "TENSOR = torch.tensor([[[1,2,3],\n",
        "                        [3,6,9],\n",
        "                        [8,2,1]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2MWaU9JKH2d"
      },
      "source": [
        "Most of the time, you won't be writing tensors by hand. Pytorch does that behind the scenes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJKPXjXbKNUR",
        "outputId": "db206f6d-9fd7-4a7e-f6d1-cd430a9849a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxpiVAQQKUjc",
        "outputId": "9526e45e-c587-44ac-9860-56c3f31c757a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bylJW3m4KcZB"
      },
      "source": [
        "number of first brackets, number of 2nd brackets, number of elements within the most inner bracket"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdi3dO9DLb1G"
      },
      "source": [
        "### Random Tensors\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.rand.html\n",
        "\n",
        "Why random Tensors?\n",
        "\n",
        "Random Tensors are important because the way many neural networks learn is that they start with tensors full of random numbers and then adjust those random numbers to better represent the data.\n",
        "\n",
        "`Start with random numbers -> look at data -> update random numbers -> look at data -> update random numbers`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC2-blcBHeqe",
        "outputId": "98842a8a-88e9-4b34-a655-ae2bc5db25fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.2207, 0.9541, 0.2189, 0.7971],\n",
              "        [0.9058, 0.1178, 0.3263, 0.3069],\n",
              "        [0.3431, 0.2859, 0.8202, 0.4323]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random tensor of size (3,4)\n",
        "random_tensor = torch.rand(3,4)\n",
        "random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf35beZ2Ipdh",
        "outputId": "93eee35f-338d-45d3-cb31-ce71f6e2fef1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "random_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x89C69OeJQsM",
        "outputId": "7b8a041c-de04-4e93-8754-8697156b3f5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a random Tensor with Similar Shape to an Image Tensor\n",
        "random_image_size_tensor = torch.rand(size =(224, 224, 3)) # Height, width, colour Channels (R,G,B) -- there is no order that is needed\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGnK-wy1USqJ",
        "outputId": "25d9cef4-8cd3-4688-db83-26f8081ef575"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8330, 0.9777, 0.8460],\n",
              "        [0.5601, 0.7013, 0.2565],\n",
              "        [0.6213, 0.0689, 0.6978]])"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.rand(size=(3,3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7FuxbS7UiID"
      },
      "source": [
        "### Zeros and Ones\n",
        "\n",
        "zero: great for masking (hiding) numbers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3aDuZNaUndN",
        "outputId": "8cfb9133-dac5-4755-8ed5-e6c00bc7d0f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a Tensor of all Zeros\n",
        "zeros = torch.zeros(size=(3,4))\n",
        "zeros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXMNhkeEVD5y",
        "outputId": "1cc9aa8d-c06e-43fd-9dab-8143c7bb637d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "zeros*random_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCNzxollVkk_",
        "outputId": "e3b4693b-6d25-43a9-9ab7-850b30cf4633"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a Tensor of All ones\n",
        "ones = torch.ones(size = (3,4))\n",
        "ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqvWDaACVuAz",
        "outputId": "0fc0614a-7d9a-446a-eaae-1b4a1f7cd8c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Default data type for this numbers is torch.float32\n",
        "ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKFmKLOVWZt2"
      },
      "source": [
        "### Creating a Range of tensors and tensor-like\n",
        "\n",
        "https://pytorch.org/docs/stable/generated/torch.arange.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oRyaSasOqar",
        "outputId": "240fc199-c128-492e-e93f-74250b258ba4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/vy/qpgsv71x71ndy195yb474r4r0000gn/T/ipykernel_6353/3135236222.py:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  torch.range(0,10)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use torch.range()\n",
        "torch.range(0,10)\n",
        "# Note that this will deprecated soon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsbXqWsjPGKD",
        "outputId": "0a759f4e-6227-43b9-afb7-5534f4d9f46a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use torch.arange()\n",
        "one_to_ten = torch.arange(1,10)\n",
        "one_to_ten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gxy4rd9MP6B6",
        "outputId": "61776685-d794-4e30-dd57-8e8b96810565"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([  0,  77, 154, 231, 308, 385, 462, 539, 616, 693, 770, 847, 924])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Using start, end, step in arange()\n",
        "torch.arange(start = 0, end = 1000, step = 77)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5zBPuXzQM5y",
        "outputId": "14c854e9-6b47-4c15-e591-53ebe11afa3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Creating tensors-like = creating a an undefined shape of a tensor\n",
        "# torch.zeros_like()\n",
        "ten_zeros = one_to_ten = torch.zeros_like(input = one_to_ten)\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tensor DataTypes\n",
        "Default tensor DataType is Float32, even when dtype = None\n",
        "\n",
        "`dtype` = what DataType is the tensor : \n",
        "https://pytorch.org/docs/stable/tensors.html - so important that DataType is the first thing that comes up\n",
        "- ***NOTE:*** Tensor DataTypes is one of the big 3 errors you'll run into with PyTorch & Deep Learning\n",
        "1. Tensors not right DataType (i.e. computing float16 with float32)\n",
        "2. Tensors not right shape (i.e. tensor multiplication)\n",
        "3. Tensors not on right device (i.e. running operations on CPU when written for GPU)\n",
        "\n",
        "`device` = What device is your tensor on\n",
        "\n",
        "`requires_grad` = Whether or not to track gradients with this tensors operation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Float 32 tensor,\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0], dtype = None, device=None, requires_grad=False)\n",
        "float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0], dtype = torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3., 6., 9.], dtype=torch.float16)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NOTE: HOW TO CONVERT A TENSOR TO A DIFFERENT DATA TYPE\n",
        "# Converting float32 to float16\n",
        "\n",
        "float_16_tensor = float_32_tensor.type(torch.float16)\n",
        "float_16_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = float_32_tensor.device\n",
        "device\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test = torch.tensor([1,2,3,4,5,6,7,8,9,10])\n",
        "test.device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Sometimes, multipling tensors of different data types actually works\n",
        "float_16_tensor * float_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([3, 6, 9], dtype=torch.int32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "int_32_tensor = torch.tensor([3,6,9], dtype= torch.int32)\n",
        "int_32_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 9., 36., 81.])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "float_32_tensor * int_32_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting Information from Tensors (Tensor Attributes)\n",
        "\n",
        "1. Tensors not right DataType - to get DataType from a tensor, can use `tensor.dtype`\n",
        "2. Tensors not right shape - to get shape from a tensor, can use `tensor.shape`\n",
        "3. Tensors not on right device - to get device from  a tensor, can use `tensor.device`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.8098, 0.0824, 0.0740, 0.5971],\n",
              "        [0.2100, 0.6878, 0.7609, 0.8886],\n",
              "        [0.7782, 0.3409, 0.6585, 0.7983]])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a Tensor\n",
        "some_tensor = torch.rand(3,4)\n",
        "some_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0.8098, 0.0824, 0.0740, 0.5971],\n",
            "        [0.2100, 0.6878, 0.7609, 0.8886],\n",
            "        [0.7782, 0.3409, 0.6585, 0.7983]])\n",
            "Data Type of some_tensor:  torch.float32\n",
            "Device of some_tensor:  cpu\n",
            "Shape of some_tensor:  torch.Size([3, 4])\n",
            "Number of Dimensions of some_tensor:  2\n",
            "Total Number of Elements in some_tensor:  12\n",
            "Size of some_tensor:  torch.Size([3, 4])\n"
          ]
        }
      ],
      "source": [
        "# Find out details about some tensor\n",
        "print(some_tensor)\n",
        "print(\"Data Type of some_tensor: \", some_tensor.dtype)\n",
        "print(\"Device of some_tensor: \", some_tensor.device)\n",
        "print(\"Shape of some_tensor: \", some_tensor.shape)\n",
        "print(\"Number of Dimensions of some_tensor: \", some_tensor.ndim)\n",
        "print(\"Total Number of Elements in some_tensor: \", some_tensor.numel())\n",
        "print(\"Size of some_tensor: \", some_tensor.size()) # This is the same as shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Manipuylation of Tensors (Tensor Operations)\n",
        "\n",
        "Tensor operation include:\n",
        "* Addition + add something to a tensor\n",
        "* Subtraction\n",
        "* Multiplication (Element-wise)\n",
        "* Division\n",
        "* Matrix Multiplication\n",
        "\n",
        "^ A neural network learns from the combination of these functions\n",
        "\n",
        "There are also built-in tensors from PyTorch however, when you can, use the operators from Python Because they are more understandable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor and add 10 to it\n",
        "tensor = torch.tensor([1,2,3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiply a tensor by 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor\n",
        "# Because we didn't reassign the tensor, the original tensor is still the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now we reassign the tensor the tensor\n",
        "tensor = tensor * 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtract 10\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([100, 200, 300])"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try out PyTorch's built-in functions\n",
        "torch.mul(tensor, 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([20, 30, 40])"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.add(tensor, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matrix Multiplication \n",
        "\n",
        "Two main ways of performing multiplication in neural networks and deep learning:\n",
        "\n",
        "1. Element-wise multiplication\n",
        "2. Matrix Multiplication aka dot product (Common tensor operation inside neural networks )\n",
        "* More infomation on how to multiply matrices: https://www.mathsisfun.com/algebra/matrix-multiplying.html\n",
        "* Fun animation: http://matrixmultiplication.xyz/\n",
        "\n",
        "\n",
        "`@` = opertator for matrix multiplication\n",
        "`matmul()` = multiplying matrices `mm()` is the same\n",
        "* If PyTorch already as a builtin in function, it is the faster version of that method\n",
        "\n",
        "There are two main rules that performing matrix multiplication needs to satisfy:\n",
        "1. The **inner dimensions** must match:\n",
        "* `(3,2) @ (3,2)` won't work\n",
        "* `(2,3) @ (3,2)` will work\n",
        "* `(3,2) @ (2,3)` will work\n",
        "2. The resulting matrix has the shape of the **Outer dimensions**:\n",
        "* `(2,3) @ (3,2)` -> `(2,2)`\n",
        "* `(3,2) @ (2,3)` -> `(3,3)`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([10, 20, 30]) *  tensor([10, 20, 30])\n",
            "Equals: tensor([100, 400, 900])\n"
          ]
        }
      ],
      "source": [
        "# Element wise multiplication\n",
        "print(tensor, \"* \", tensor)\n",
        "print(f\"Equals: {tensor * tensor}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1400)"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication\n",
        "torch.matmul(tensor, tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1400"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication by hand\n",
        "10*10 + 20*20 + 30*30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 174 μs, sys: 62 μs, total: 236 μs\n",
            "Wall time: 229 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(1400)"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1400)\n",
            "CPU times: user 608 μs, sys: 792 μs, total: 1.4 ms\n",
            "Wall time: 759 μs\n"
          ]
        }
      ],
      "source": [
        "%%time \n",
        "# How long does it take to multiply two tensors\n",
        "\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "    value += tensor[i] * tensor[i]\n",
        "print(value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 163 μs, sys: 51 μs, total: 214 μs\n",
            "Wall time: 185 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(1400)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)\n",
        "#*Note: It is so much faster to use PyTorch's built-in functions than to write your own functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### One of the most common errors in Deep Learning is the shape error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Because the inner dimensions don't match\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x4 and 3x4)"
          ]
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3,4), torch.rand(3,4))\n",
        "# Because the inner dimensions don't match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.4523, 0.4510, 0.4215],\n",
              "        [0.7861, 0.8714, 0.8826],\n",
              "        [0.0393, 0.0404, 0.0386]])"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.matmul(torch.rand(3,2), torch.rand(2,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m tensor_A \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m      3\u001b[0m                          [\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m],\n\u001b[1;32m      4\u001b[0m                          [\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m6\u001b[39m]])\n\u001b[1;32m      5\u001b[0m tensor_B \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m7\u001b[39m,\u001b[38;5;241m10\u001b[39m],\n\u001b[1;32m      6\u001b[0m                          [\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m11\u001b[39m],\n\u001b[1;32m      7\u001b[0m                          [\u001b[38;5;241m9\u001b[39m,\u001b[38;5;241m12\u001b[39m]])\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_B\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# torch.mm() is the same as torch.matmul()\u001b[39;00m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (3x2 and 3x2)"
          ]
        }
      ],
      "source": [
        "# Shapes for matrix multiplication\n",
        "tensor_A = torch.tensor([[1,2],\n",
        "                         [3,4],\n",
        "                         [5,6]])\n",
        "tensor_B = torch.tensor([[7,10],\n",
        "                         [8,11],\n",
        "                         [9,12]])\n",
        "\n",
        "torch.mm(tensor_A, tensor_B) # torch.mm() is the same as torch.matmul()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tensor_A.shape, tensor_B.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To Fix our tensor shape issues, we can manupliate the shape of one of our tensors using a ***transpose***\n",
        "\n",
        "A ***Transpose*** switches the axes or dimensions of a given tensor\n",
        "`<tensor>.T` `.T` stands for transpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7,  8,  9],\n",
              "         [10, 11, 12]]),\n",
              " torch.Size([2, 3]))"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B.T, tensor_B.T.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 7, 10],\n",
              "         [ 8, 11],\n",
              "         [ 9, 12]]),\n",
              " torch.Size([3, 2]))"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor_B, tensor_B.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original shapes: tensor_A: torch.Size([3, 2]), tensor_B: torch.Size([3, 2])\n",
            "New shapes: tesnor_A = torch.Size([3, 2]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
            "Multiplying: torch.Size([3, 2]) @ torch.Size([2, 3]) <- inner dimensions must match\n",
            "Output:\n",
            "\n",
            "tensor([[ 27,  30,  33],\n",
            "        [ 61,  68,  75],\n",
            "        [ 95, 106, 117]])\n",
            "\n",
            "Output shape: torch.Size([3, 3])\n"
          ]
        }
      ],
      "source": [
        "# The mm operation works when tensor_B is transposed\n",
        "print(f\"Original shapes: tensor_A: {tensor_A.shape}, tensor_B: {tensor_B.shape}\")\n",
        "print(f\"New shapes: tesnor_A = {tensor_A.shape} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
        "print(f\"Multiplying: {tensor_A.shape} @ {tensor_B.T.shape} <- inner dimensions must match\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.mm(tensor_A, tensor_B.T)\n",
        "print(output) \n",
        "print(f\"\\nOutput shape: {output.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensor Aggregation: finding the min, max, mean, sum, etc of a tensor\n",
        "\n",
        "It's called tensor aggregation because you are going from a large to small amount of numbers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]), torch.int64)"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor\n",
        "x = torch.arange(1,100,10)\n",
        "x, x.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(1), tensor(1))"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the min\n",
        "torch.min(x), x.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(91), tensor(91))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the max\n",
        "torch.max(x), x.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[63], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Find the mean \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m, x\u001b[38;5;241m.\u001b[39mmean()\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
          ]
        }
      ],
      "source": [
        "# Find the mean \n",
        "torch.mean(x), x.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(46.), tensor(46.), tensor(46.), tensor(46.))"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Now, converting the tensor to float to get mean\n",
        "torch.mean(x.float()), x.float().mean(), torch.mean(x.type(torch.float32)), x.type(torch.float32).mean()\n",
        "# NOTE torch.mean() function requires a tensor of float32 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(460), tensor(460))"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the sum\n",
        "torch.sum(x), x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Finding the positional minimum and maximum\n",
        "\n",
        "At what index do we find the min and max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0)"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# At what index does the min value occur.\n",
        "x.argmin()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(9)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# At what index does the max value occur\n",
        "x.argmax()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reshaping, stacking, seqeezing and unsqueezing tensors\n",
        "\n",
        "* Reshaping - reshapes an input tensor to a defined shape\n",
        "* View - return a view of an input tesnor of a certain shape but keep the same memory as the original tensor\n",
        "* Stacking - combining multiple tensors on top of each other ***vstack*** or **hstack** side by side:  https://pytorch.org/docs/stable/generated/torch.stack.html\n",
        "* Squeeze - removes all `1` dimensions from a tensor: https://pytorch.org/docs/stable/generated/torch.squeeze.html\n",
        "* Unsqueexe - add a `1` dimension to a target tensor\n",
        "* Permute - Return a view of the input with dimensions permuted (swapped) in a certain way\n",
        "\n",
        "main point of all of these is to manipulate our tensors in some way, to change their shape or change their dimernsion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's create a tensor\n",
        "a = torch.arange(1.,10.)\n",
        "a, a.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]]), torch.Size([1, 10]))"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra Dimension with .reshape()\n",
        "a_reshaped = x.reshape(1,10)\n",
        "a_reshaped, a_reshaped.shape\n",
        "# NOTE: The reshape has to be a multiple of the original shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([9]))"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the view\n",
        "z = a.view(1, 9)\n",
        "z, a.shape\n",
        "# View shares the same memory as the original tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
              " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NOTE: Changing z will change a (because a view of a tensor shares the same memory as the original tensor)\n",
        "z[:,0] = 5\n",
        "z, a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
              "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Stack tensors on top of each other\n",
        "a_stacked = torch.stack([a,a,a,a], dim = 0)\n",
        "a_stacked"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[5., 5., 5., 5.],\n",
              "        [2., 2., 2., 2.],\n",
              "        [3., 3., 3., 3.],\n",
              "        [4., 4., 4., 4.],\n",
              "        [5., 5., 5., 5.],\n",
              "        [6., 6., 6., 6.],\n",
              "        [7., 7., 7., 7.],\n",
              "        [8., 8., 8., 8.],\n",
              "        [9., 9., 9., 9.]])"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_stacked_1 = torch.stack([a,a,a,a], dim = 1)\n",
        "a_stacked_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-2, 1], but got 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[77], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a_stacked_2 \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43ma\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m a_stacked_2\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-2, 1], but got 2)"
          ]
        }
      ],
      "source": [
        "a_stacked_2 = torch.stack([a,a,a,a], dim = 2)\n",
        "a_stacked_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]])\n",
            "Previous shape: torch.Size([1, 10])\n",
            "\n",
            "New tensor: tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
            "New shape: torch.Size([10])\n"
          ]
        }
      ],
      "source": [
        "# torch.squeeze() = removes all single dimensions from a target tensor\n",
        "print(f\"Previous tensor: {a_reshaped}\")\n",
        "print(f\"Previous shape: {a_reshaped.shape}\")\n",
        "\n",
        "# Remove extra dimensions from a_reshaped\n",
        "a_squeezed = a_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {a_squeezed}\")\n",
        "print(f\"New shape: {a_squeezed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous tensor: tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])\n",
            "Previous shape: torch.Size([10]) \n",
            "\n",
            "New tensor: tensor([[ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]])\n",
            "New shape: torch.Size([1, 10])\n"
          ]
        }
      ],
      "source": [
        "# torch.unsqueeze() = adds a single dim to a target tensor at a specific dim (dimension)\n",
        "print(f\"Previous tensor: {a_squeezed}\")\n",
        "print(f\"Previous shape: {a_squeezed.shape} \")\n",
        "\n",
        "# Add an extra dimension to a_squeezed\n",
        "a_unsqueezed = a_squeezed.unsqueeze(dim = 0)\n",
        "print(f\"\\nNew tensor: {a_unsqueezed}\")\n",
        "print(f\"New shape: {a_unsqueezed.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.permute() = rearranges the dimensions of a target tensor in a specified order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 10])"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_reshaped.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_reshaped.squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([10])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a_reshaped.squeeze().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# torch.permute - rearranges the dimensions of a target tensor in a specified order\n",
        "a_original = torch.rand(size=(224, 224, 3)) # Height, Width, Colour Channels (R,G,B)\n",
        "\n",
        "# Permute the original tensor to rearrange the axis (or dim) order\n",
        "a_permuted = a_original.permute(2,0,1) # New order: Colour Channels, Height, Width\n",
        "# By index\n",
        "print(f\"Previous shape: {a_original.shape}\")\n",
        "print(f\"New shape: {a_permuted.shape}\") # New shape: (3, 224, 224)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Indexing (Selecting Data From Tensors)\n",
        "\n",
        "Indexing with PyTorch is similar to indexing with NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create a Tensor\n",
        "import torch\n",
        "x = torch.arange(1,10).reshape(1,3,3)\n",
        "x, x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3],\n",
              "        [4, 5, 6],\n",
              "        [7, 8, 9]])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on our new tensor\n",
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on the middle bracket (dim = 1)\n",
        "x[0][0]\n",
        "x[0,0] \n",
        "# These two are the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(1)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's index on the most inner bracket (Last dim)\n",
        "x[0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can also use the slicing operator \":\" to select \"All\" of a target dimension\n",
        "x[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of 0th and 1st dimensions but but only index 1  of 2nd dimension\n",
        "x[:,:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get all values of the 0th dimension but only index 1 of the 1st dimension and 2nd dimension\n",
        "x[:,1,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get index 0 of 0th dim and 1st dim and all values of 2nd dim\n",
        "x[0,0,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(9)\n",
            "tensor([3, 6, 9])\n"
          ]
        }
      ],
      "source": [
        "# Index on x to return 9\n",
        "print(x[0,2,2])\n",
        "\n",
        "# Index on x to return 3, 6, 9\n",
        "print(x[0,:,2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "NumPy is a popular scientific Python numerical computing library\n",
        "\n",
        "And because of this, PyTorch has functionalioty to interactive with it\n",
        "\n",
        "* Data in NumPy, want in PyTorch -> `torch.from_numpy(ndarray)`\n",
        "* PyTorch tensor -> NumPy -> `torch.tensor.numpy()`\n",
        "\n",
        "NumPy's default DataType is float64\n",
        "PyTorch's default DataType is float32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "array = np.arange(1.0,8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "array.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PyTorch reflects the data type of the numpy array unless specified otherwise\n",
        "tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.arange(1.0, 8.0).dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# change the value of array, what will this do to `tensor`?\n",
        "array = array + 1\n",
        "array, tensor\n",
        "# Tensor remains the same because it is a new value in memory and not a reference to the numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tensor to numpy array\n",
        "tensor = torch.ones(7)\n",
        "numpy_tensor = tensor.numpy()\n",
        "tensor, numpy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change the tensor, what happens to `numpy_tensor`?\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor\n",
        "# tensor and numpy_tensor don't share the same memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reproducibility ( Trying to take random out of random)\n",
        "\n",
        "In short, how a neural network learns:\n",
        "\n",
        "`start with random numbers -> tensor operations -> update random numbers to try and make them better representations of the data -> again -> again -> again...`\n",
        "\n",
        "To reduce the randomness in neural networks and PyTorch comes the concept of a ***random seed***.\n",
        "\n",
        "Essentially what the random seed does is \"Flavour\" the randomness\n",
        "\n",
        "If you are creating random manuel tensors, instiate each time before creating another tensor \n",
        "\n",
        "https://pytorch.org/docs/stable/notes/randomness.html\n",
        "\n",
        "https://en.wikipedia.org/wiki/Random_seed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First random tensor (A):\n",
            "tensor([[0.8397, 0.9785, 0.1665, 0.7554],\n",
            "        [0.7056, 0.7950, 0.8292, 0.1026],\n",
            "        [0.3783, 0.4847, 0.8205, 0.9297]])\n",
            "\n",
            "Second random tensor (B):\n",
            "tensor([[0.0754, 0.3855, 0.0937, 0.4379],\n",
            "        [0.6380, 0.0964, 0.1096, 0.6023],\n",
            "        [0.8512, 0.5685, 0.2976, 0.4812]])\n",
            "\n",
            "Are they equal? == tensor([[False, False, False, False],\n",
            "        [False, False, False, False],\n",
            "        [False, False, False, False]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# Create two random tensors\n",
        "random_tensor_A = torch.rand(3,4)\n",
        "random_tensor_B = torch.rand(3,4)\n",
        "\n",
        "print(f\"First random tensor (A):\\n{random_tensor_A}\")\n",
        "print(f\"\\nSecond random tensor (B):\\n{random_tensor_B}\")\n",
        "print(f\"\\nAre they equal? == {random_tensor_A == random_tensor_B}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First random tensor (C):\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Second random tensor (D):\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Are they equal? == tensor([[True, True, True, True],\n",
            "        [True, True, True, True],\n",
            "        [True, True, True, True]])\n"
          ]
        }
      ],
      "source": [
        "# Let's make some random but reproducible tensors\n",
        "import torch\n",
        "\n",
        "# Set the random seed\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3,4)\n",
        "\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "random_tensor_D = torch.rand(3,4)\n",
        "\n",
        "\n",
        "print(f\"First random tensor (C):\\n{random_tensor_C}\")\n",
        "print(f\"\\nSecond random tensor (D):\\n{random_tensor_D}\")\n",
        "print(f\"\\nAre they equal? == {random_tensor_C == random_tensor_D}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Running tensors and PyTorch objects on the GPUs (and making faster computations)\n",
        "\n",
        "GPUs = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Getting a GPU\n",
        "\n",
        "1. Easiest - Use Google Colab to get a GPU (options to upgrade as well )\n",
        "2. Use your own GPU - takes a litte bit of setup and requires the investment of purchasing a GPU. there are tons of options. Check out this post for more info or getting started on researching GPU options: https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/\n",
        "3. Use cloud computing - GCP, AWS, Azure. These services allow you to rent computers on the cloud and access them\n",
        "\n",
        "For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documenations \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For PyTorch since it is capable of running compute on the GPU or CPU, it's best practice to:\n",
        "* Mac: https://pytorch.org/docs/stable/notes/mps.html\n",
        "* coda: https://pytorch.org/docs/stable/notes/cuda.html#best-practices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup device agnostic code\n",
        "# for Coda\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # or mps\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# NOTE: for mac\n",
        "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Putting Tensors (and models) on the GPU\n",
        "\n",
        "The reason we want our tensors/models on the GPU is because using a CPU results in faster computations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3]) cpu\n",
            "tensor([1, 2, 3]) cpu\n"
          ]
        }
      ],
      "source": [
        "# Create a tenso (default on the CPU)\n",
        "tensor = torch.tensor([1,2,3], device = \"cpu\")\n",
        "tensor_default = torch.tensor([1,2,3])\n",
        "\n",
        "print(tensor, tensor.device)\n",
        "print(tensor, tensor.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move tensor to GPU (if available)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "0 is the index on the GPU we are using"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Moving tensors to the CPU\n",
        "\n",
        "BECAUSE NumPy only works on CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[110], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# If Tensor is on GPU, can't transform it to NumPy\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtensor_on_gpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert mps:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ],
      "source": [
        "# If Tensor is on GPU, can't transform it to NumPy\n",
        "tensor_on_gpu.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "execution_count": 113,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# To fix the GPU tensor with NumPy issue, we can first set it to the CPU\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4 μs, sys: 0 ns, total: 4 μs\n",
            "Wall time: 5.96 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3], device='mps:0')"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 2 μs, sys: 1 μs, total: 3 μs\n",
            "Wall time: 2.15 μs\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "execution_count": 115,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%%time\n",
        "tensor_default"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
